# Sprint 8 Findings: Hybrid Regex + NLP Approach for Skill & Topic Identification

**Date:** 18/06/2025

## Method
- Combined regex-based code token extraction with NLP (spaCy) for comments/docstrings.
- Used a mapping from code tokens (e.g., 'plt', 'scatter', 'read_csv') to skill categories (e.g., 'visualization', 'data loading').
- Evaluated the approach using a set of test cases for skill/topic detection in code snippets.

## Issues Encountered
- Pure NLP approaches (spaCy) missed many code-specific skills/topics.
- Keyword-only approaches lacked context and semantic understanding.
- Initial hybrid approach still missed some skills (e.g., 'visualization') due to lack of token-to-skill mapping.

## Solutions Provided
- Added a `CODE_TOKEN_TO_SKILL` mapping to improve detection of skills like 'visualization'.
- Combined direct token matching, mapping, and NLP for comments to maximize coverage.

## Pain Points
- Regex-based extraction may still miss skills/topics if code is highly obfuscated or uses non-standard naming.
- Some false positives may remain if keywords are used in unrelated contexts.
- Hybrid approach adds complexity to the codebase and testing.

## Lessons Learnt
- Combining multiple approaches (regex, mapping, NLP) yields better results than any single method.
- Code-specific patterns and libraries are crucial for accurate skill detection.
- Automated tests are essential for validating improvements and catching regressions.

## Limitations
- Still relies on a predefined skills/topics list; new skills require manual updates.
- Does not fully capture deep semantic meaning or intent in code.
- May not generalize to all programming languages or code styles without further tuning.

## Next Steps
- Expand the `CODE_TOKEN_TO_SKILL` mapping for broader coverage.
- Explore integration of code-specific ML models (e.g., CodeBERT, tree-sitter, Code Llama) for deeper semantic analysis.
- Add confidence scoring and ranking for detected skills.
- Evaluate on a larger, more diverse codebase.

## In-Scope Opportunities
- Further refinement of the hybrid approach for Python and similar languages.
- Integration into the main skill categorization pipeline and Streamlit app.
- Automated reporting of skill detection metrics.

## Out-of-Scope Opportunities
- Full semantic code understanding (e.g., intent inference, code summarization).
- Support for all programming languages without language-specific tuning.
- Real-time skill detection in large codebases or streaming code analysis.

---

# Sprint 9: Code Llama via Ollama vs Hybrid Approach

## Method
- Used Code Llama (via Ollama) to extract skills/topics from code by prompting the model and parsing its natural language output.
- Compared the results to the hybrid regex+NLP approach on the same code snippet.

## Results
- **Code Llama skills:**
  - Skills: Data preprocessing with Pandas (dropping missing values), Machine learning model training with Scikit-learn, Data visualization with Matplotlib
  - Libraries: pandas, sklearn, matplotlib
- **Hybrid approach skills:**
  - {'data engineering', 'visualization', 'data cleaning', 'data loading', 'ml modeling'}

## Lessons Learned
- Code Llama provides a more descriptive, context-aware, and human-readable output, listing both skills and libraries.
- The hybrid approach gives a precise, structured set of skills, but is limited to the predefined mapping and may miss nuanced or contextual skills.
- Code Llama's output may require additional parsing to extract structured skill/topic lists, but is more flexible and adaptable to new code patterns.
- Hybrid approach is deterministic and fast, but less flexible.

## Recommendations
- Use Code Llama for exploratory analysis, nuanced skill extraction, and when context is important.
- Use the hybrid approach for fast, structured, and repeatable skill detection, especially when a controlled vocabulary is needed.
- Consider combining both approaches for best results: use Code Llama for context and discovery, and the hybrid approach for structured reporting. 